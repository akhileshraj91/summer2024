{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ruamel.yaml\n",
    "import math\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from matplotlib import cm\n",
    "import warnings\n",
    "import yaml\n",
    "yaml_format = ruamel.yaml.YAML()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dir():\n",
    "    # current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    current_dir = os.getcwd()\n",
    "    print(current_dir)\n",
    "    return os.path.join(current_dir, \"experiment_data\", \"Control\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derived_papi(PAPI_data):\n",
    "    DERIVED = {}\n",
    "    DERIVED['TOT_INS_PER_CYC'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_TOT_INS']['instantaneous_value']) / np.array(PAPI_data['PAPI_TOT_CYC']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_TOT_INS'].time)\n",
    "    })\n",
    "    DERIVED['TOT_CYC_PER_INS'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_TOT_CYC']['instantaneous_value']) / np.array(PAPI_data['PAPI_TOT_INS']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_TOT_CYC'].time)\n",
    "    })\n",
    "    DERIVED['L3_TCM_PER_TCA'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_L3_TCM']['instantaneous_value']) / np.array(PAPI_data['PAPI_L3_TCA']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_L3_TCM'].time)\n",
    "    })  \n",
    "    DERIVED['TOT_STL_PER_CYC'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_RES_STL']['instantaneous_value']) / np.array(PAPI_data['PAPI_TOT_CYC']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_RES_STL'].time)\n",
    "    })\n",
    "    \n",
    "    # Create a mask for non-NaN values across all keys\n",
    "    mask = ~DERIVED['TOT_INS_PER_CYC']['value'].isna()  # Start with one key to create the mask\n",
    "    for key in DERIVED:\n",
    "        mask &= ~DERIVED[key]['value'].isna()  # Combine masks for all keys\n",
    "\n",
    "    for key in DERIVED:\n",
    "        DERIVED[key] = DERIVED[key][mask]  # Filter each DataFrame using the combined mask\n",
    "\n",
    "    return DERIVED\n",
    "\n",
    "def calculate_power_with_wraparound(current, previous, time_diff, wraparound_value=262143.328850):\n",
    "    diff = current - previous\n",
    "    if diff < 0:  # Wraparound detected\n",
    "        diff = (wraparound_value - previous) + current\n",
    "    return diff / time_diff\n",
    "\n",
    "def compute_power(pubEnergy):\n",
    "    power = {}\n",
    "    geopm_sensor0 = geopm_sensor1 = pd.DataFrame({'timestamp':[],'value':[]})\n",
    "    for i,row in pubEnergy.iterrows():\n",
    "        if i%2 == 0:\n",
    "            geopm_sensor0 = pd.concat([geopm_sensor0, pd.DataFrame([{'timestamp': row['time'], 'value': row['value']}])], ignore_index=True)\n",
    "        else:\n",
    "            geopm_sensor1 = pd.concat([geopm_sensor1, pd.DataFrame([{'timestamp': row['time'], 'value': row['value']}])], ignore_index=True)\n",
    "\n",
    "\n",
    "    power['geopm_power_0'] = pd.DataFrame({\n",
    "        'timestamp': geopm_sensor0['timestamp'][1:],  # Add timestamps\n",
    "        'power': [\n",
    "            calculate_power_with_wraparound(\n",
    "                geopm_sensor0['value'][i],\n",
    "                geopm_sensor0['value'][i-1],\n",
    "                geopm_sensor0['timestamp'][i] - geopm_sensor0['timestamp'][i-1]\n",
    "            ) for i in range(1, len(geopm_sensor0))\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Apply the same logic to geopm_power_1\n",
    "    power['geopm_power_1'] = pd.DataFrame({\n",
    "        'timestamp': geopm_sensor1['timestamp'][1:],  # Add timestamps\n",
    "        'power': [\n",
    "            calculate_power_with_wraparound(\n",
    "                geopm_sensor1['value'][i],\n",
    "                geopm_sensor1['value'][i-1],\n",
    "                geopm_sensor1['timestamp'][i] - geopm_sensor1['timestamp'][i-1]\n",
    "            ) for i in range(1, len(geopm_sensor1))\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    min_length = min(len(power['geopm_power_0']), len(power['geopm_power_1']))\n",
    "    geopm_power_0 = power['geopm_power_0'][:min_length]\n",
    "    geopm_power_1 = power['geopm_power_1'][:min_length]\n",
    "\n",
    "    average_power = pd.DataFrame({\n",
    "        'timestamp': geopm_power_0['timestamp'],  # Use the timestamp from geopm_power_0\n",
    "        'average_power': [(p0 + p1) / 2 for p0, p1 in zip(geopm_power_0['power'], geopm_power_1['power'])]\n",
    "    })\n",
    "    average_power['elapsed_time'] = average_power['timestamp'] - average_power['timestamp'].iloc[0]\n",
    "    power['average_power'] = average_power\n",
    "    return power\n",
    "\n",
    "def measure_progress(progress_data, energy_data):\n",
    "    Progress_DATA = {} \n",
    "    progress_sensor = pd.DataFrame(progress_data)\n",
    "    first_sensor_point = min(energy_data['average_power']['timestamp'].iloc[0], progress_sensor['time'][0])\n",
    "    progress_sensor['elapsed_time'] = progress_sensor['time'] - first_sensor_point  # New column for elapsed time\n",
    "    # progress_sensor = progress_sensor.set_index('elapsed_time')\n",
    "    performance_elapsed_time = progress_sensor.elapsed_time\n",
    "    # Add performance_frequency as a new column in progress_sensor\n",
    "    frequency_values = [\n",
    "        progress_data['value'].iloc[t] / (performance_elapsed_time[t] - performance_elapsed_time[t-1]) for t in range(1, len(performance_elapsed_time))\n",
    "    ]\n",
    "    \n",
    "    # Ensure the frequency_values length matches the index length\n",
    "    frequency_values = [0] + frequency_values  # Prepend a 0 for the first index\n",
    "    progress_sensor['frequency'] = frequency_values\n",
    "    upsampled_timestamps= energy_data['average_power']['timestamp']\n",
    "    \n",
    "    # true_count = (progress_sensor['time'] <= upsampled_timestamps.iloc[0]).sum()\n",
    "\n",
    "    progress_frequency_median = pd.DataFrame({'median': np.nanmedian(progress_sensor['frequency'].where(progress_sensor['time'] <= upsampled_timestamps.iloc[0])), 'timestamp': upsampled_timestamps.iloc[0]}, index=[0])\n",
    "    for t in range(1, len(upsampled_timestamps)):\n",
    "        progress_frequency_median = pd.concat([progress_frequency_median, pd.DataFrame({'median': [np.nanmedian(progress_sensor['frequency'].where((progress_sensor['time'] >= upsampled_timestamps.iloc[t-1]) & (progress_sensor['time'] <= upsampled_timestamps.iloc[t])))],\n",
    "        'timestamp': [upsampled_timestamps.iloc[t]]})], ignore_index=True)\n",
    "    progress_frequency_median['elapsed_time'] = progress_frequency_median['timestamp'] - progress_frequency_median['timestamp'].iloc[0]\n",
    "    # Assign progress_frequency_median as a new column\n",
    "    Progress_DATA['progress_sensor'] = progress_sensor\n",
    "    Progress_DATA['progress_frequency_median'] = progress_frequency_median\n",
    "    return Progress_DATA\n",
    "\n",
    "def collect_papi(PAPI_data):\n",
    "    PAPI = {}\n",
    "    for scope in PAPI_data['scope'].unique():\n",
    "        # Extract the string between the 3rd and 4th dots\n",
    "        scope_parts = scope.split('.')\n",
    "        if len(scope_parts) > 4:  # Ensure there are enough parts\n",
    "            extracted_scope = scope_parts[3]\n",
    "            # Aggregate the data for the extracted scope using pd.concat\n",
    "            PAPI[extracted_scope] = PAPI_data[PAPI_data['scope'] == scope]\n",
    "            instantaneous_values = [0] + [PAPI[extracted_scope]['value'].iloc[k] - PAPI[extracted_scope]['value'].iloc[k-1] for k in range(1,len(PAPI[extracted_scope]))]\n",
    "            # Normalize the instantaneous values between 0 and 10\n",
    "            # min_val = min(instantaneous_values)\n",
    "            # max_val = max(instantaneous_values)\n",
    "            PAPI[extracted_scope]['instantaneous_value'] = instantaneous_values\n",
    "            PAPI[extracted_scope]['elapsed_time'] = PAPI[extracted_scope]['time'] - PAPI[extracted_scope]['time'].iloc[0]\n",
    "    return PAPI\n",
    "\n",
    "\n",
    "def generate_PCAP(PCAP_data):\n",
    "    for row in PCAP_data.iterrows():\n",
    "        if row[1]['time'] == 0:\n",
    "            PCAP_data = PCAP_data.drop(row[0])\n",
    "\n",
    "\n",
    "    PCAP_data['elapsed_time'] = PCAP_data['time'] - PCAP_data['time'].iloc[0]\n",
    "    return PCAP_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhileshraj/Desktop/summer2024/main_codes\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = get_data_dir()\n",
    "root,folders,files = next(os.walk(DATA_DIR))\n",
    "test_results = {}\n",
    "for APP in folders:\n",
    "    APP_DIR = os.path.join(DATA_DIR, APP)\n",
    "    test_results[APP] = {}\n",
    "    for file in next(os.walk(APP_DIR))[2]:\n",
    "        test_results[APP][file] = {}\n",
    "        if file.endswith('.tar'):\n",
    "            tar_path = os.path.join(APP_DIR, file)\n",
    "            extract_dir = os.path.join(APP_DIR, file[:-4])  \n",
    "            \n",
    "            if not os.path.exists(extract_dir):\n",
    "                os.makedirs(extract_dir)\n",
    "            \n",
    "            with tarfile.open(tar_path, 'r') as tar:\n",
    "                tar.extractall(path=extract_dir)\n",
    "            \n",
    "        pubProgress = pd.read_csv(f'{extract_dir}/progress.csv')\n",
    "        pubEnergy = pd.read_csv(f'{extract_dir}/energy.csv')\n",
    "        pubPAPI = pd.read_csv(f'{extract_dir}/papi.csv')\n",
    "        pubPCAP = pd.read_csv(f'{extract_dir}/PCAP_file.csv')\n",
    "        test_results[APP][file]['energy'] = pubEnergy\n",
    "        test_results[APP][file]['power'] = compute_power(pubEnergy)\n",
    "        test_results[APP][file]['progress'] = measure_progress(pubProgress,test_results[APP][file]['power'])\n",
    "        test_results[APP][file]['papi'] = collect_papi(pubPAPI)\n",
    "        test_results[APP][file]['PCAP'] = generate_PCAP(pubPCAP)\n",
    "        test_results[APP][file]['derived_papi'] = derived_papi(test_results[APP][file]['papi'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App: ones-stream-add\n",
      "Total execution time is:  47.999961614608765\n",
      "Total energy consumed is:  6311.441193402499\n",
      "Energy Consumed as per the energy file is:  time       48.999975\n",
      "scope       1.000000\n",
      "value    6311.778259\n",
      "dtype: float64\n",
      "App: ones-stream-scale\n",
      "Total execution time is:  34.999939918518066\n",
      "Total energy consumed is:  4481.127529596217\n",
      "Energy Consumed as per the energy file is:  time       35.999934\n",
      "scope       1.000000\n",
      "value    4481.468079\n",
      "dtype: float64\n",
      "App: ones-stream-triad\n",
      "Total execution time is:  48.99991822242737\n",
      "Total energy consumed is:  5923.130582710902\n",
      "Energy Consumed as per the energy file is:  time       49.999929\n",
      "scope       1.000000\n",
      "value    5923.475342\n",
      "dtype: float64\n",
      "App: ones-stream-full\n",
      "Total execution time is:  172.00088810920715\n",
      "Total energy consumed is:  23338.09408462567\n",
      "Energy Consumed as per the energy file is:  time       173.000904\n",
      "scope        1.000000\n",
      "value    23338.798767\n",
      "dtype: float64\n",
      "App: ones-npb-ep\n",
      "Total execution time is:  73.99998807907104\n",
      "Total energy consumed is:  9897.285642528257\n",
      "Energy Consumed as per the energy file is:  time         75.000036\n",
      "scope         1.000000\n",
      "value   -252245.909363\n",
      "dtype: float64\n",
      "App: ones-stream-copy\n",
      "Total execution time is:  34.00003123283386\n",
      "Total energy consumed is:  4353.946686422531\n",
      "Energy Consumed as per the energy file is:  time       34.999990\n",
      "scope       1.000000\n",
      "value    4354.371094\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for app in test_results.keys():\n",
    "    for trace in test_results[app].keys():\n",
    "        print(f\"App: {app}\")\n",
    "        print(\"Total execution time is: \", test_results[app][trace]['power']['average_power']['elapsed_time'].iloc[-1])\n",
    "        print(\"Total energy consumed is: \", test_results[app][trace]['power']['average_power']['average_power'].sum())\n",
    "        # print(\"Energy Consumed as per the energy file is: \", test_results[app][trace]['energy'].iloc[-1]-test_results[app][trace]['energy'].iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
