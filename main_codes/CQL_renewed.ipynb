{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ruamel.yaml import YAML\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import math\n",
    "import warnings\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import utils\n",
    "import gym\n",
    "import argparse\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dir():\n",
    "    # current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    current_dir = os.getcwd()\n",
    "    print(current_dir)\n",
    "    return os.path.join(current_dir, \"experiment_data\", \"data_generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Format the current time\n",
    "output_dir = f'./output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "loss_file = open(f'{output_dir}/losses_seed_{current_time}.csv', mode='w', newline='')\n",
    "loss_writer = csv.writer(loss_file)\n",
    "loss_writer.writerow(['iteration', 'actor_loss', 'critic_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derived_papi(PAPI_data):\n",
    "    DERIVED = {}\n",
    "    DERIVED['TOT_INS_PER_CYC'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_TOT_INS']['instantaneous_value']) / np.array(PAPI_data['PAPI_TOT_CYC']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_TOT_INS'].time)\n",
    "    })\n",
    "    DERIVED['TOT_CYC_PER_INS'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_TOT_CYC']['instantaneous_value']) / np.array(PAPI_data['PAPI_TOT_INS']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_TOT_CYC'].time)\n",
    "    })\n",
    "    DERIVED['L3_TCM_PER_TCA'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_L3_TCM']['instantaneous_value']) / np.array(PAPI_data['PAPI_L3_TCA']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_L3_TCM'].time)\n",
    "    })  \n",
    "    DERIVED['TOT_STL_PER_CYC'] = pd.DataFrame({\n",
    "        'value': np.array(PAPI_data['PAPI_RES_STL']['instantaneous_value']) / np.array(PAPI_data['PAPI_TOT_CYC']['instantaneous_value']),\n",
    "        'timestamp': np.array(PAPI_data['PAPI_RES_STL'].time)\n",
    "    })\n",
    "    \n",
    "    # Create a mask for non-NaN values across all keys\n",
    "    mask = ~DERIVED['TOT_INS_PER_CYC']['value'].isna()  # Start with one key to create the mask\n",
    "    for key in DERIVED:\n",
    "        mask &= ~DERIVED[key]['value'].isna()  # Combine masks for all keys\n",
    "\n",
    "    for key in DERIVED:\n",
    "        DERIVED[key] = DERIVED[key][mask]  # Filter each DataFrame using the combined mask\n",
    "\n",
    "    return DERIVED\n",
    "\n",
    "def calculate_power_with_wraparound(current, previous, time_diff, wraparound_value=262143.328850):\n",
    "    diff = current - previous\n",
    "    if diff < 0:  # Wraparound detected\n",
    "        diff = (wraparound_value - previous) + current\n",
    "    return diff / time_diff\n",
    "\n",
    "def compute_power(pubEnergy):\n",
    "    power = {}\n",
    "    geopm_sensor0 = geopm_sensor1 = pd.DataFrame({'timestamp':[],'value':[]})\n",
    "    for i,row in pubEnergy.iterrows():\n",
    "        if i%2 == 0:\n",
    "            geopm_sensor0 = pd.concat([geopm_sensor0, pd.DataFrame([{'timestamp': row['time'], 'value': row['value']}])], ignore_index=True)\n",
    "        else:\n",
    "            geopm_sensor1 = pd.concat([geopm_sensor1, pd.DataFrame([{'timestamp': row['time'], 'value': row['value']}])], ignore_index=True)\n",
    "\n",
    "\n",
    "    power['geopm_power_0'] = pd.DataFrame({\n",
    "        'timestamp': geopm_sensor0['timestamp'][1:],  # Add timestamps\n",
    "        'power': [\n",
    "            calculate_power_with_wraparound(\n",
    "                geopm_sensor0['value'][i],\n",
    "                geopm_sensor0['value'][i-1],\n",
    "                geopm_sensor0['timestamp'][i] - geopm_sensor0['timestamp'][i-1]\n",
    "            ) for i in range(1, len(geopm_sensor0))\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Apply the same logic to geopm_power_1\n",
    "    power['geopm_power_1'] = pd.DataFrame({\n",
    "        'timestamp': geopm_sensor1['timestamp'][1:],  # Add timestamps\n",
    "        'power': [\n",
    "            calculate_power_with_wraparound(\n",
    "                geopm_sensor1['value'][i],\n",
    "                geopm_sensor1['value'][i-1],\n",
    "                geopm_sensor1['timestamp'][i] - geopm_sensor1['timestamp'][i-1]\n",
    "            ) for i in range(1, len(geopm_sensor1))\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    min_length = min(len(power['geopm_power_0']), len(power['geopm_power_1']))\n",
    "    geopm_power_0 = power['geopm_power_0'][:min_length]\n",
    "    geopm_power_1 = power['geopm_power_1'][:min_length]\n",
    "\n",
    "    average_power = pd.DataFrame({\n",
    "        'timestamp': geopm_power_0['timestamp'],  # Use the timestamp from geopm_power_0\n",
    "        'average_power': [(p0 + p1) / 2 for p0, p1 in zip(geopm_power_0['power'], geopm_power_1['power'])]\n",
    "    })\n",
    "    average_power['elapsed_time'] = average_power['timestamp'] - average_power['timestamp'].iloc[0]\n",
    "    power['average_power'] = average_power\n",
    "    return power\n",
    "\n",
    "def measure_progress(progress_data, energy_data):\n",
    "    Progress_DATA = {} \n",
    "    progress_sensor = pd.DataFrame(progress_data)\n",
    "    first_sensor_point = min(energy_data['average_power']['timestamp'].iloc[0], progress_sensor['time'][0])\n",
    "    progress_sensor['elapsed_time'] = progress_sensor['time'] - first_sensor_point  # New column for elapsed time\n",
    "    # progress_sensor = progress_sensor.set_index('elapsed_time')\n",
    "    performance_elapsed_time = progress_sensor.elapsed_time\n",
    "    # Add performance_frequency as a new column in progress_sensor\n",
    "    frequency_values = [\n",
    "        progress_data['value'].iloc[t] / (performance_elapsed_time[t] - performance_elapsed_time[t-1]) for t in range(1, len(performance_elapsed_time))\n",
    "    ]\n",
    "    \n",
    "    # Ensure the frequency_values length matches the index length\n",
    "    frequency_values = [0] + frequency_values  # Prepend a 0 for the first index\n",
    "    progress_sensor['frequency'] = frequency_values\n",
    "    upsampled_timestamps= energy_data['average_power']['timestamp']\n",
    "    \n",
    "    # true_count = (progress_sensor['time'] <= upsampled_timestamps.iloc[0]).sum()\n",
    "\n",
    "    progress_frequency_median = pd.DataFrame({'median': np.nanmedian(progress_sensor['frequency'].where(progress_sensor['time'] <= upsampled_timestamps.iloc[0])), 'timestamp': upsampled_timestamps.iloc[0]}, index=[0])\n",
    "    for t in range(1, len(upsampled_timestamps)):\n",
    "        progress_frequency_median = pd.concat([progress_frequency_median, pd.DataFrame({'median': [np.nanmedian(progress_sensor['frequency'].where((progress_sensor['time'] >= upsampled_timestamps.iloc[t-1]) & (progress_sensor['time'] <= upsampled_timestamps.iloc[t])))],\n",
    "        'timestamp': [upsampled_timestamps.iloc[t]]})], ignore_index=True)\n",
    "    progress_frequency_median['elapsed_time'] = progress_frequency_median['timestamp'] - progress_frequency_median['timestamp'].iloc[0]\n",
    "    # Assign progress_frequency_median as a new column\n",
    "    Progress_DATA['progress_sensor'] = progress_sensor\n",
    "    Progress_DATA['progress_frequency_median'] = progress_frequency_median\n",
    "    return Progress_DATA\n",
    "\n",
    "def collect_papi(PAPI_data):\n",
    "    PAPI = {}\n",
    "    for scope in PAPI_data['scope'].unique():\n",
    "        # Extract the string between the 3rd and 4th dots\n",
    "        scope_parts = scope.split('.')\n",
    "        if len(scope_parts) > 4:  # Ensure there are enough parts\n",
    "            extracted_scope = scope_parts[3]\n",
    "            # Aggregate the data for the extracted scope using pd.concat\n",
    "            PAPI[extracted_scope] = PAPI_data[PAPI_data['scope'] == scope]\n",
    "            instantaneous_values = [0] + [PAPI[extracted_scope]['value'].iloc[k] - PAPI[extracted_scope]['value'].iloc[k-1] for k in range(1,len(PAPI[extracted_scope]))]\n",
    "            # Normalize the instantaneous values between 0 and 10\n",
    "            # min_val = min(instantaneous_values)\n",
    "            # max_val = max(instantaneous_values)\n",
    "            PAPI[extracted_scope]['instantaneous_value'] = instantaneous_values\n",
    "            PAPI[extracted_scope]['elapsed_time'] = PAPI[extracted_scope]['time'] - PAPI[extracted_scope]['time'].iloc[0]\n",
    "    return PAPI\n",
    "\n",
    "\n",
    "def generate_PCAP(PCAP_data):\n",
    "    for row in PCAP_data.iterrows():\n",
    "        if row[1]['time'] == 0:\n",
    "            PCAP_data = PCAP_data.drop(row[0])\n",
    "\n",
    "\n",
    "    PCAP_data['elapsed_time'] = PCAP_data['time'] - PCAP_data['time'].iloc[0]\n",
    "    return PCAP_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhileshraj/Desktop/summer2024/main_codes\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = get_data_dir()\n",
    "root,folders,files = next(os.walk(DATA_DIR))\n",
    "training_data = {}\n",
    "for APP in folders:\n",
    "    APP_DIR = os.path.join(DATA_DIR, APP)\n",
    "    training_data[APP] = {}\n",
    "    for file in next(os.walk(APP_DIR))[2]:\n",
    "        training_data[APP][file] = {}\n",
    "        if file.endswith('.tar'):\n",
    "            tar_path = os.path.join(APP_DIR, file)\n",
    "            extract_dir = os.path.join(APP_DIR, file[:-4])  \n",
    "            \n",
    "            if not os.path.exists(extract_dir):\n",
    "                os.makedirs(extract_dir)\n",
    "            \n",
    "            with tarfile.open(tar_path, 'r') as tar:\n",
    "                tar.extractall(path=extract_dir)\n",
    "            \n",
    "        pubProgress = pd.read_csv(f'{extract_dir}/progress.csv')\n",
    "        pubEnergy = pd.read_csv(f'{extract_dir}/energy.csv')\n",
    "        pubPAPI = pd.read_csv(f'{extract_dir}/papi.csv')\n",
    "        pubPCAP = pd.read_csv(f'{extract_dir}/PCAP_file.csv')\n",
    "        # with open(f'{extract_dir}/parameters.yaml', 'r') as f:\n",
    "        #     yaml = YAML(typ='safe', pure=True)\n",
    "        #     parameters = yaml.load(f)\n",
    "        #     PCAP = parameters['PCAP']\n",
    "        # training_data['data']['PCAP'] = pd.read_csv(f'{extract_dir}/PCAP_file.csv')\n",
    "        training_data[APP][file]['power'] = compute_power(pubEnergy)\n",
    "        training_data[APP][file]['progress'] = measure_progress(pubProgress,training_data[APP][file]['power'])\n",
    "        training_data[APP][file]['papi'] = collect_papi(pubPAPI)\n",
    "        training_data[APP][file]['PCAP'] = generate_PCAP(pubPCAP)\n",
    "        training_data[APP][file]['derived_papi'] = derived_papi(training_data[APP][file]['papi'])   \n",
    "        # print(training_data[APP][file]['PCAP'] )    \n",
    "# training_data = normalize(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APP = 'ones-stream-add'\n",
    "# file = list(training_data[APP].keys())[0]\n",
    "# training_data[APP][file]['derived_papi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_S = 1\n",
    "ACTIONS = [78.0, 83.0, 89.0, 95.0, 101.0, 107.0, 112.0, 118.0, 124.0, 130.0, 136.0, 141.0, 147.0, 153.0, 159.0, 165.0]\n",
    "exec_steps = 10000    \n",
    "TOTAL_ACTIONS = len(ACTIONS)                                                                                                  # Total clock cycles needed for the execution of program.\n",
    "ACTION_MIN = min(ACTIONS)                                                                                                    # Minima of control space\n",
    "ACTION_MAX = max(ACTIONS)                                                                                                     # Maxima of control space\n",
    "ACT_MID = ACTION_MIN + (ACTION_MAX - ACTION_MIN) / 2                                                                    # Midpoint of the control space to compute the normalized action space\n",
    "# OBS_MAX = 300                                                                                                           # Maxima of observation space (performance)\n",
    "# OBS_MIN = 0                           \n",
    "OBS_MIN = np.zeros((7,))  # Shape should be (7,)\n",
    "OBS_MAX = np.array([300,165,10,10,10,10,10])                                                                                 # Minima of observation space\n",
    "OBS_MID = OBS_MIN + (OBS_MAX - OBS_MIN) / 2\n",
    "EXEC_ITERATIONS = 10000\n",
    "TOTAL_OBS = OBS_MAX - OBS_MIN\n",
    "# print(TOTAL_ACTIONS)\n",
    "OBS_ONEHOT = 'onehot'\n",
    "OBS_RANDOM = 'random'\n",
    "OBS_SMOOTH = 'smooth'\n",
    "\n",
    "\n",
    "class SYS(object):\n",
    "    def __init__(self,observation_type=OBS_ONEHOT,dim_obs=1,teps=0.0):\n",
    "        super(SYS,self).__init__()\n",
    "\n",
    "        self.num_actions = TOTAL_ACTIONS\n",
    "        self.action_space = gym.spaces.Discrete(len(ACTIONS))  # Use the length of the ACTIONS list for discrete actions\n",
    "        # Map the selected index to the corresponding action\n",
    "        self.actions = ACTIONS  # Store the actions for later use\n",
    "        self.observation_space = gym.spaces.Box(low=OBS_MIN, high=OBS_MAX, shape=(7,), dtype=np.float32)  # Infinite observation space with 8 dimensions\n",
    "\n",
    "    \n",
    "    def reward(self, s, a, ns, measured_power):\n",
    "        \"\"\" \n",
    "        Returns the reward (float)\n",
    "        \"\"\"\n",
    "        # measured_power = A[cluster] * a + B[cluster]\n",
    "        if ns > 0:\n",
    "            # self.current_step += ns\n",
    "            # reward = - 5*a\n",
    "            # reward = 2*ns/(((a)/measured_power)+measured_power) # Check the behaviour across the states\n",
    "            reward = ns/(a**2+1)\n",
    "            # reward = 5*a\n",
    "        else:\n",
    "            reward = -100\n",
    "        # print(reward)\n",
    "        return reward\n",
    "\n",
    "weighting_only = False\n",
    "dataset_composition = 'random'\n",
    "dataset_size = 1000\n",
    "env_type = 'random'\n",
    "env = SYS(observation_type=env_type, dim_obs=8, teps=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_data(df, time_column, start_time, end_time):\n",
    "    return df[(df[time_column] > start_time) & (df[time_column] <= end_time)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(td, app, trace, start_time, end_time):\n",
    "    # print(app,trace,start_time,end_time)\n",
    "    ROI_progress = get_roi_data(td[app][trace]['progress']['progress_frequency_median'], 'timestamp', start_time, end_time)\n",
    "    ROI_measured_power = get_roi_data(td[app][trace]['power']['average_power'], 'timestamp', start_time, end_time)\n",
    "    TOT_INS_PER_CYC = get_roi_data(td[app][trace]['derived_papi']['TOT_INS_PER_CYC'], 'timestamp', start_time, end_time)\n",
    "    L3_TCM_PER_TCA = get_roi_data(td[app][trace]['derived_papi']['L3_TCM_PER_TCA'], 'timestamp', start_time, end_time)\n",
    "    TOT_STL_PER_CYC = get_roi_data(td[app][trace]['derived_papi']['TOT_STL_PER_CYC'], 'timestamp', start_time, end_time)\n",
    "    return (\n",
    "        ROI_progress['median'].mean() if not ROI_progress.empty else 0,\n",
    "        ROI_measured_power['average_power'].mean() if not ROI_measured_power.empty else 0,\n",
    "        TOT_INS_PER_CYC['value'].mean() if not TOT_INS_PER_CYC.empty else 0,\n",
    "        L3_TCM_PER_TCA['value'].mean() if not L3_TCM_PER_TCA.empty else 0,\n",
    "        TOT_STL_PER_CYC['value'].mean() if not TOT_STL_PER_CYC.empty else 0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881\n",
      "Training dataset has been saved to /Users/akhileshraj/Desktop/summer2024/main_codes/experiment_data/data_generation/training_dataset.csv\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training_data_csv = pd.read_csv('./merged_data.csv')\n",
    "# PCAP = 0\n",
    "# CURRENT_PRO = 0\n",
    "# NEXT_PRO = 0\n",
    "training_dataset = []\n",
    "old_PCAP = 0\n",
    "action_set = []\n",
    "# Helper function to get state\n",
    "\n",
    "\n",
    "# state_definition = [progress, measured_power, previous_PCAP, 'PAPI_L3_TCA', 'PAPI_TOT_INS', 'PAPI_TOT_CYC', 'PAPI_RES_STL', 'PAPI_L3_TCM']\n",
    "initial_progress = 0\n",
    "initial_power = 40\n",
    "initial_PAPI = np.zeros(5)\n",
    "state = (initial_progress,initial_power,initial_PAPI)\n",
    "t1 = float('-inf')\n",
    "for app in training_data:\n",
    "    for trace in training_data[app]:\n",
    "        pcap_data = training_data[app][trace]['PCAP']\n",
    "        for i, row in pcap_data.iterrows():\n",
    "            t2 = row['time']\n",
    "            \n",
    "            # Get current state\n",
    "            state = get_state(training_data, app, trace, t1, t2)\n",
    "            \n",
    "            # Get next state (look ahead to next row)\n",
    "            if i + 1 < len(pcap_data):\n",
    "                t3 = pcap_data.iloc[i + 1]['time']\n",
    "                next_state = get_state(training_data, app, trace, t2, t3)\n",
    "            else:\n",
    "                next_state = state  # Use current state if it's the last row\n",
    "            \n",
    "            action = row['value']  # Assuming PCAP is in the 'value' column\n",
    "            \n",
    "            # Calculate the reward\n",
    "            reward = env.reward(state[0], action, next_state[0], state[1])\n",
    "            \n",
    "            # Add to training dataset\n",
    "            training_dataset.append((state, action, reward, next_state))\n",
    "            \n",
    "            t1 = t2\n",
    "print(len(training_dataset))\n",
    "# training_dataset = [row for row in training_dataset if not any(pd.isna(value) for value in row)]\n",
    "\n",
    "# Define the CSV file name and path\n",
    "csv_file_name = 'training_dataset.csv'\n",
    "csv_file_path = os.path.join(DATA_DIR, csv_file_name)\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    csv_writer.writerow(['Progress', 'Power', 'TOT_INS_PER_CYC', 'L3_TCM_PER_TCA', 'TOT_STL_PER_CYC', \n",
    "                         'Action', 'Reward', \n",
    "                         'Next_Progress', 'Next_Power', 'Next_TOT_INS_PER_CYC', 'Next_L3_TCM_PER_TCA', 'Next_STL_PER_CYC'])\n",
    "    \n",
    "    for state, action, reward, next_state in training_dataset:\n",
    "        # print(state,action,reward,next_state)\n",
    "        if not (np.isnan(state).any() or np.isnan(action) or np.isnan(reward) or np.isnan(next_state).any()):\n",
    "            row = list(state) + [action, reward] + list(next_state)\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "print(f\"Training dataset has been saved to {csv_file_path}\")\n",
    "\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = f'{DATA_DIR}/training_dataset.csv'\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "loaded_data = pd.read_csv(csv_file_path)\n",
    "print(len(loaded_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# Convert the DataFrame back to the original format (list of tuples)\n",
    "training_dataset_loaded = [\n",
    "    (\n",
    "        tuple(row[:5]),  # State\n",
    "        row[5],          # Action\n",
    "        row[6],          # Reward\n",
    "        tuple(row[7:])   # Next State\n",
    "    )\n",
    "    for row in loaded_data.values\n",
    "]\n",
    "\n",
    "print(len(training_dataset_loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_observations(env):\n",
    "    obs = []\n",
    "    for s in range(env.num_states):\n",
    "        obs.append(env.observation(s))\n",
    "    return np.stack(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNetwork(torch.nn.Module):\n",
    "  def __init__(self, env, layers=[20,20]):\n",
    "    super(FCNetwork, self).__init__()\n",
    "    # self.all_observations = torch.tensor(stack_observations(env), dtype=torch.float32)\n",
    "    dim_input = 5\n",
    "    dim_output = env.num_actions\n",
    "    net_layers = []\n",
    "\n",
    "    dim = dim_input\n",
    "    for i, layer_size in enumerate(layers):\n",
    "      net_layers.append(torch.nn.Linear(dim, layer_size))\n",
    "      net_layers.append(torch.nn.ReLU())\n",
    "      dim = layer_size\n",
    "    net_layers.append(torch.nn.Linear(dim, dim_output))\n",
    "    self.layers = net_layers\n",
    "    self.network = torch.nn.Sequential(*net_layers)\n",
    "\n",
    "  def forward(self, states):\n",
    "    # observations = torch.index_select(self.all_observations, 0, states)\n",
    "    states_tensor = torch.tensor(states, dtype=torch.float32)  # Ensure the correct dtype\n",
    "    return self.network(states_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(list_of_tensors, list_of_indices):\n",
    "  s, a, ns, r = [], [], [], []\n",
    "  for idx in list_of_indices:\n",
    "    s.append(list_of_tensors[idx][0])\n",
    "    a.append(list_of_tensors[idx][1])\n",
    "    r.append(list_of_tensors[idx][2])\n",
    "    ns.append(list_of_tensors[idx][3])\n",
    "  s = np.array(s)\n",
    "  a = np.array(a)\n",
    "  ns = np.array(ns)\n",
    "  r = np.array(r)\n",
    "  return s, a, ns, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_qvalues_cql_sampled(env, s, a, target_values, network, optimizer, cql_alpha=0.1, num_steps=50, weights=None):\n",
    "    # train with a sampled dataset\n",
    "    target_qvalues = torch.tensor(target_values, dtype=torch.float32)\n",
    "    s = torch.tensor(s, dtype=torch.int64)\n",
    "    # a = torch.tensor(a, dtype=torch.int64)\n",
    "    a_indices = np.array([ACTIONS.index(action) for action in a])\n",
    "    a_indices = torch.tensor(a_indices, dtype=torch.int64)\n",
    "    pred_qvalues = network(s)\n",
    "    logsumexp_qvalues = torch.logsumexp(pred_qvalues, dim=-1)\n",
    "\n",
    "    pred_qvalues = pred_qvalues.gather(1, a_indices.reshape(-1,1)).squeeze()\n",
    "    cql_loss = logsumexp_qvalues - pred_qvalues\n",
    "\n",
    "    loss = torch.mean((pred_qvalues - target_qvalues)**2)\n",
    "    loss = loss + cql_alpha * torch.mean(cql_loss)\n",
    "\n",
    "    network.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # pred_qvalues = network(torch.arange(env.num_states))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_qvalues_cql(q_values, network, optimizer, num_steps=50, cql_alpha=0.1, weights=None):\n",
    "    # regress onto q_values (aka projection)\n",
    "    q_values_tensor = torch.tensor(q_values, dtype=torch.float32)\n",
    "    for _ in range(num_steps):\n",
    "       # Eval the network at each state\n",
    "      pred_qvalues = network(torch.arange(q_values.shape[0]))\n",
    "      if weights is None:\n",
    "        loss = torch.mean((pred_qvalues - q_values_tensor)**2)\n",
    "      else:\n",
    "        loss = torch.mean(weights*(pred_qvalues - q_values_tensor)**2)\n",
    "\n",
    "      # Add cql_loss\n",
    "      # You can have two variants of this loss, one where data q-values\n",
    "      # also maximized (CQL-v2), and one where only the large Q-values\n",
    "      # are pushed down (CQL-v1) as covered in the tutorial\n",
    "      cql_loss = torch.logsumexp(pred_qvalues, dim=-1, keepdim=True) # - pred_qvalues\n",
    "      loss = loss + cql_alpha * torch.mean(weights * cql_loss)\n",
    "      network.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    return pred_qvalues.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_backup_sparse_sampled(env, network, s, a, ns, r, discount=0.99):\n",
    "  with torch.no_grad():  \n",
    "    q_values_ns = network(ns)\n",
    "  values = np.max(q_values_ns.detach().numpy(), axis=-1)\n",
    "  target_value = r + discount * values\n",
    "  return target_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conservative_q_iteration(env,\n",
    "                             network,\n",
    "                             num_itrs=100,\n",
    "                             project_steps=50,\n",
    "                             cql_alpha=0.1,\n",
    "                             render=False,\n",
    "                             weights=None,\n",
    "                             sampled=False,\n",
    "                             training_dataset=None,\n",
    "                             **kwargs):\n",
    "  \"\"\"\n",
    "  Runs Conservative Q-iteration.\n",
    "\n",
    "  Args:\n",
    "    env: A GridEnv object.\n",
    "    num_itrs (int): Number of FQI iterations to run.\n",
    "    project_steps (int): Number of gradient steps used for projection.\n",
    "    cql_alpha (float): Value of weight on the CQL coefficient.\n",
    "    render (bool): If True, will plot q-values after each iteration.\n",
    "    sampled (bool): Whether to use sampled datasets for training or not.\n",
    "    training_dataset (list): list of (s, a, r, ns) pairs\n",
    "  \"\"\"\n",
    "\n",
    "  optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "\n",
    "  # q_values = np.zeros((dS, dA)) #Initializing the Q-values for getting the target values\n",
    "  # q_values = network(s)\n",
    "  for i in range(num_itrs):\n",
    "    for j in range(project_steps):\n",
    "      training_idx = np.random.choice(np.arange(len(training_dataset)), size=64)\n",
    "      s, a, ns, r = get_tensors(training_dataset, training_idx)\n",
    "      target_values = q_backup_sparse_sampled(env, network, s, a, ns, r, **kwargs)\n",
    "      project_qvalues_cql_sampled(\n",
    "          env, s, a, target_values, network, optimizer,\n",
    "          cql_alpha=cql_alpha, weights=None,\n",
    "      )\n",
    "      # if j == project_steps - 1:\n",
    "      #   q_values = intermed_values\n",
    "  return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#@title Run conservative Q-iteration (or CQL) with finite data\n",
    "\n",
    "# Use a tabular or feedforward NN approximator\n",
    "network = FCNetwork(env, layers=[20, 20])\n",
    "#network = TabularNetwork(env)\n",
    "\n",
    "cql_alpha_val = 0.1 # @param {type:\"slider\", min:0.0, max:10.0, step:0.01}\n",
    "weights = None\n",
    "print (weighting_only)\n",
    "# Run Q-iteration\n",
    "trained_net = conservative_q_iteration(env, network,\n",
    "                                    num_itrs=1000, discount=0.95, cql_alpha=cql_alpha_val,\n",
    "                                    weights=weights, render=False,\n",
    "                                    sampled=not(weighting_only),\n",
    "                                    training_dataset=training_dataset_loaded)\n",
    "\n",
    "# Compute and plot the value function\n",
    "# v_values = np.max(q_values, axis=1)\n",
    "# plot_s_values(env, v_values, title='Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
